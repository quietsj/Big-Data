<div align="center"> <font size="6"> <b> Hadoop知识点总结 </b> </font></div>

---

## 目录
1. [Hadoop简介](#hadoop简介)


### Hadoop简介

+ Hadoop特点
    + 可靠性：多台机器构成集群，部分机器发生故障，剩余机器可以继续对外服务
    + 高效性：成百上千台机器一起计算
    + 可扩展性：可以不断的往集群中增加机器
+ Hadoop项目结构
    ![//](../images/屏幕截图%202021-07-16%20235153.png)


### 分布式文件系统HDFS

+ HDFS相关概念
    + 块：对大文件进行切割，默认块大小64M
        + 支持大规模文件存储
        + 简化系统设计
        + 适合数据备份
    + 名称节点：整个HDFS集群的管家，是数据目录，记录元数据
        + 元数据
            + 文件是什么
            + 文件被分割成多少块
            + 每个块和文件是怎么映射的
            + 每个块存储在那个服务器上面
        + FsImage：保存系统文件树
            + 文件的负责等级
            + 修改和访问时间
            + 访问权限
            + 块大小组成及组成文件的块
        + EditLog：记录对数据进行的诸如创建、删除、重命名等操作
    + 第二名称节点：EditLog不断增大时的合并处理
    + 数据节点：数据最终保存到本地Linux文件系统
+ HDFS存储原理
    + 冗余数据保存
        + 加快数据传输速度
        + 容易检查数据错误
        + 保证数据可靠性
    + 数据保存策略
        + 第一块：集群内放在上传的数据节点，集群外放在较空闲剩余空间大的节点
        + 第二块：放在第一块的不同机架
        + 第三块：第一块相同机架的其它节点
        + 其它块随机存放
    + 数据的错误与恢复
        + 名称节点出故障：从第二个名称节点读取冷备份数据
        + 数据节点出故障：将数据迁移到其它节点
        + 数据错误：客户端校验码不一致，从其它节点读取备份数据
+ HDFS读数据
    + 简单代码
    ![//](../images/屏幕截图%202021-07-17%20181539.png)
    + 底层执行过程
    ![//](../images/屏幕截图%202021-07-17%20180623.png)
+ HDFS写数据
    + 底层执行过程
    ![//](../images/屏幕截图%202021-07-17%20183833.png)
    
    
### 分布式数据库Hbase

+ Hbase简介
    + Hbase是一个高可靠、高性能、面向列、可伸缩的分布式数据库
    + Hbase解决大数据实时处理问题
    + Hbase特点
        + 数据类型都为字节数组
        + 基于列存储
        + 设计之初只有对行键的索引
        + 更新数据时之前的数据保留
        + 扩展性好
+ Hbas数据模型
    + 稀疏的多维度的排序的映射表
    + 4个维度定位数据：行键、列族、列限定符（列）、时间戳
    + 键值数据库
    + 以行键、时间戳、列族物理存储
+ Hbase实现原理
    + 三个组件
        + 库函数：一般用于链接每个客户端
        + Master服务器：充当管家的作用
        + Region服务器：负责存储不同的Region
    + 表在慢慢变大的过程中分裂成多个Region
        + Region的实际大小，取决于单台服务器的有效处理能力
        + 同一个Region不会分裂到不同的Region服务器上
    + 三层结构
    ![//](../images/屏幕截图%202021-07-19%20233554.png)


### 分布式并行计算MapReduce

+ 分布式并行编程

+ MapReduce模型简介
    + 计算向数据靠容的理念
    + Master/slave架构
        + 一个Master服务器
            + 作业跟踪器JobTracker，负责整个作业的调度和处理以及失败的恢复
        + 若干个slave
            + 执行具体任务的TaskTracker，负责接受JobTracker的指令完成具体的任务处理
    + Map/Reduce函数
    ![//](../images/屏幕截图%202021-07-21%20002015.png)
    
+ MapReduce体系结构
    + Client客户端
        + 提交用户编写的程序到JobTracker
        + 查看当前提交作业的状态
    + JobTracker
        + 负责资源的监控和作业的调度
        + 监控底层的其它的TaskTracker以及当前运行的Job健康状态
        + 监测到失败的将任务转移到其它节点运行
    + TackTracker
        + 执行具体的任务，一般接受JobTracker发送过来的命令
        + 把自己的资源使用以及运行进度，通过心跳的方式发送给JobTracker
    + TaskScheduler
        + 执行具体的任务调度
        
+ MpaReduce各个执行流程
    + InputFormat
        + 从分布式文件系统读取数据，进行格式验证
        + 逻辑上切分数据
    + RecordRead
        + 从HDFS中读取具体的数据
        + 将数据以<key, value>形式输出
    + Map
        + 输入<key, value>
        + 执行逻辑后输出<key, value>
    + Shuffle
        + 执行分区，排序，合并
        + 输出<key, value_list>
    + Reduce
        + 输入<key, value_list>
        + 执行逻辑后输出<key, value>
    + OutputFormat
        + 检查格式
        + 写入HDFS文件
    + 相关概念
        + 切片大小：一般等于块的大小
        + Map数量等于分片数量
        + Reduce数量通常微小于reduce任务槽(slot)的数量
+ Shuffle过程原理
    + Shuffle过程流程图
    ![//](../images/屏幕截图%202021-07-22%20000223.png)
    + Map端的Shuffle过程
    ![//](../images/屏幕截图%202021-07-22%20001519.png)
        + 溢写：达到缓存比后写入磁盘
        + 合并：非必须，用户可以自己定义，注意合并不影响最终结果，比如相加，最大值等
        + 归并：将多个文件组成分区的有序文件
        + 分区：对应的Reduce任务
    + Reduce端的Shuffle过程
    ![//](../images/屏幕截图%202021-07-22%20002836.png)
        + 归并成<key, value_list>
    + 中间结果之间写入在本地磁盘
